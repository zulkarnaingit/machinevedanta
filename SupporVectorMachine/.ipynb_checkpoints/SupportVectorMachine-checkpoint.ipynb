{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b694e9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d767999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f06df042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>deposit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2343</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1042</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1467</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1270</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1389</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2476</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>579</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>673</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11157</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11158</th>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>733</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11159</th>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11160</th>\n",
       "      <td>43</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11161</th>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>628</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11162 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  job  marital  education  default  balance  housing  loan  contact  \\\n",
       "0       59    0        1          1        0     2343        1     0        2   \n",
       "1       56    0        1          1        0       45        0     0        2   \n",
       "2       41    9        1          1        0     1270        1     0        2   \n",
       "3       55    7        1          1        0     2476        1     0        2   \n",
       "4       54    0        1          2        0      184        0     0        2   \n",
       "...    ...  ...      ...        ...      ...      ...      ...   ...      ...   \n",
       "11157   33    1        2          0        0        1        1     0        0   \n",
       "11158   39    7        1          1        0      733        0     0        2   \n",
       "11159   32    9        2          1        0       29        0     0        0   \n",
       "11160   43    9        1          1        0        0        0     1        0   \n",
       "11161   34    9        1          1        0        0        0     0        0   \n",
       "\n",
       "       day  month  duration  campaign  pdays  previous  poutcome  deposit  \n",
       "0        5      8      1042         1     -1         0         3        1  \n",
       "1        5      8      1467         1     -1         0         3        1  \n",
       "2        5      8      1389         1     -1         0         3        1  \n",
       "3        5      8       579         1     -1         0         3        1  \n",
       "4        5      8       673         2     -1         0         3        1  \n",
       "...    ...    ...       ...       ...    ...       ...       ...      ...  \n",
       "11157   20      0       257         1     -1         0         3        0  \n",
       "11158   16      6        83         4     -1         0         3        0  \n",
       "11159   19      1       156         2     -1         0         3        0  \n",
       "11160    8      8         9         2    172         5         0        0  \n",
       "11161    9      5       628         1     -1         0         3        0  \n",
       "\n",
       "[11162 rows x 17 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to lod the dataset\n",
    "df=pd.read_csv('bank.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00d9ce3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age          int64\n",
       "job          int64\n",
       "marital      int64\n",
       "education    int64\n",
       "default      int64\n",
       "balance      int64\n",
       "housing      int64\n",
       "loan         int64\n",
       "contact      int64\n",
       "day          int64\n",
       "month        int64\n",
       "duration     int64\n",
       "campaign     int64\n",
       "pdays        int64\n",
       "previous     int64\n",
       "poutcome     int64\n",
       "deposit      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4559f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age          0.0\n",
       "job          0.0\n",
       "marital      0.0\n",
       "education    0.0\n",
       "default      0.0\n",
       "balance      0.0\n",
       "housing      0.0\n",
       "loan         0.0\n",
       "contact      0.0\n",
       "day          0.0\n",
       "month        0.0\n",
       "duration     0.0\n",
       "campaign     0.0\n",
       "pdays        0.0\n",
       "previous     0.0\n",
       "poutcome     0.0\n",
       "deposit      0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()/df.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3243ded7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.heatmap(df.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3ec28fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5873\n",
       "1    5289\n",
       "Name: deposit, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['deposit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70064b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# #make countplot for deposit\n",
    "sb.countplot(data=df,x='deposit')\n",
    "f=df['deposit'].value_counts()\n",
    "plt.yticks(f)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0e510db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select  input and output\n",
    "X=df.drop('deposit',axis=1) #input\n",
    "Y=df['deposit'] #output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "199d366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e7ab15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7813, 16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "426d94b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3349, 16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab54fa1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7813,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a289adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3349,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "808abd8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7813, 16), (3349, 16))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we use standardScaler\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "428cf56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d77282d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an object for STandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf9e08bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34defe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=ss.fit_transform(X_train)\n",
    "X_test=ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4087cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.76552511,  0.15596991, -0.32335267, ..., -0.48203214,\n",
       "        -0.35894691,  0.52287872],\n",
       "       [ 1.16824122, -1.0830671 , -0.32335267, ..., -0.48203214,\n",
       "        -0.35894691,  0.52287872],\n",
       "       [ 1.33637636,  1.39500692, -0.32335267, ..., -0.48203214,\n",
       "        -0.35894691,  0.52287872],\n",
       "       ...,\n",
       "       [-1.18565083, -0.77330785, -0.32335267, ..., -0.48203214,\n",
       "        -0.35894691,  0.52287872],\n",
       "       [-0.00870481, -1.39282635,  1.27358436, ...,  3.07264515,\n",
       "         4.3350541 , -0.47109973],\n",
       "       [-0.42904267, -1.0830671 , -0.32335267, ..., -0.48203214,\n",
       "        -0.35894691,  0.52287872]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97e304fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a user define function :passing argument and returning  value\n",
    "def create_model(model):\n",
    "    model.fit(X_train,Y_train) #rtrain model with 70% of data\n",
    "    y_pred=model.predict(X_test) #test the model with 30% of data\n",
    "    #generate rport \n",
    "    print(classification_report(Y_test,y_pred))\n",
    "#confusion matrix\n",
    "    print(confusion_matrix(Y_test,y_pred))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ca84ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#creat an object for logisticRegression\n",
    "lr=LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd51da6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84c169c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1760\n",
      "           1       0.79      0.77      0.78      1589\n",
      "\n",
      "    accuracy                           0.80      3349\n",
      "   macro avg       0.80      0.80      0.80      3349\n",
      "weighted avg       0.80      0.80      0.80      3349\n",
      "\n",
      "[[1441  319]\n",
      " [ 359 1230]]\n"
     ]
    }
   ],
   "source": [
    "#calling the function with help of logisticRegression\n",
    "\n",
    "lr=create_model(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f613e70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision Tree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aff31346",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create object for Decision Tree classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63f9ef00",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc=DecisionTreeClassifier(random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbb68652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1,101):\n",
    "#     dtc=DecisionTreeClassifier(random_state=i)\n",
    "#     print(\"random state\",i)\n",
    "    \n",
    "#     dtc=create_model(dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f65aa5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1760\n",
      "           1       0.79      0.78      0.78      1589\n",
      "\n",
      "    accuracy                           0.80      3349\n",
      "   macro avg       0.79      0.79      0.79      3349\n",
      "weighted avg       0.80      0.80      0.80      3349\n",
      "\n",
      "[[1424  336]\n",
      " [ 349 1240]]\n"
     ]
    }
   ],
   "source": [
    "dtc=create_model(dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da43797d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Information_Gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>0.077727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>job</td>\n",
       "      <td>0.038054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>marital</td>\n",
       "      <td>0.018294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>education</td>\n",
       "      <td>0.014744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>default</td>\n",
       "      <td>0.000713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>balance</td>\n",
       "      <td>0.084855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>housing</td>\n",
       "      <td>0.043811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>loan</td>\n",
       "      <td>0.006772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>contact</td>\n",
       "      <td>0.062115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>day</td>\n",
       "      <td>0.075494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>month</td>\n",
       "      <td>0.097783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>duration</td>\n",
       "      <td>0.347553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>campaign</td>\n",
       "      <td>0.021594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pdays</td>\n",
       "      <td>0.059605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>previous</td>\n",
       "      <td>0.008588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>poutcome</td>\n",
       "      <td>0.042297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Features  Information_Gain\n",
       "0         age          0.077727\n",
       "1         job          0.038054\n",
       "2     marital          0.018294\n",
       "3   education          0.014744\n",
       "4     default          0.000713\n",
       "5     balance          0.084855\n",
       "6     housing          0.043811\n",
       "7        loan          0.006772\n",
       "8     contact          0.062115\n",
       "9         day          0.075494\n",
       "10      month          0.097783\n",
       "11   duration          0.347553\n",
       "12   campaign          0.021594\n",
       "13      pdays          0.059605\n",
       "14   previous          0.008588\n",
       "15   poutcome          0.042297"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creat a dictanary   \n",
    "\n",
    "dict={\"Features\":X.columns,'Information_Gain':dtc.feature_importances_}\n",
    "\n",
    "\n",
    "df1=pd.DataFrame(dict)\n",
    "df1\n",
    "\n",
    "#default is quit less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "baf76e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #create  a tree \n",
    "# from sklearn import tree\n",
    "# feature=X.columns\n",
    "# plt.figure(figsize=(20,20))\n",
    "# _=tree.plot_tree(dtc,feature_names=feature,filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0424aa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to overcome overfit we have 2 pruning technique\n",
    "#1 Max_depth\n",
    "#2 min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b650020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     1.max_depth: inbuilt parameter of decision tree classifier class(minlen=1 and maxlen=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3267cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.75      0.80      1760\n",
      "           1       0.75      0.86      0.80      1589\n",
      "\n",
      "    accuracy                           0.80      3349\n",
      "   macro avg       0.80      0.80      0.80      3349\n",
      "weighted avg       0.81      0.80      0.80      3349\n",
      "\n",
      "[[1316  444]\n",
      " [ 228 1361]]\n"
     ]
    }
   ],
   "source": [
    "#max depth parameter\n",
    "#create and object for DecisionTreeclassifier\n",
    "# for i in range(1,9):\n",
    "#     dtc1=DecisionTreeClassifier(random_state=43,max_depth=i)\n",
    "#     print(\"Max Depth\",i)\n",
    "#     dtc1=create_model(dtc1)\n",
    "\n",
    "dtc1=DecisionTreeClassifier(random_state=43,max_depth=5)\n",
    "dtc1=create_model(dtc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cfed81ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.75      0.80      1760\n",
      "           1       0.75      0.86      0.80      1589\n",
      "\n",
      "    accuracy                           0.80      3349\n",
      "   macro avg       0.80      0.80      0.80      3349\n",
      "weighted avg       0.81      0.80      0.80      3349\n",
      "\n",
      "[[1316  444]\n",
      " [ 228 1361]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dtc1=DecisionTreeClassifier(random_state=43,max_depth=5)\n",
    "dtc1=create_model(dtc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11e6ea95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Information_Gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>0.026846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>job</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>marital</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>education</td>\n",
       "      <td>0.002853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>default</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>balance</td>\n",
       "      <td>0.001040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>housing</td>\n",
       "      <td>0.066337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>loan</td>\n",
       "      <td>0.003762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>contact</td>\n",
       "      <td>0.119728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>day</td>\n",
       "      <td>0.003512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>month</td>\n",
       "      <td>0.052438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>duration</td>\n",
       "      <td>0.576413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>campaign</td>\n",
       "      <td>0.000982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pdays</td>\n",
       "      <td>0.078652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>previous</td>\n",
       "      <td>0.016312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>poutcome</td>\n",
       "      <td>0.051127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Features  Information_Gain\n",
       "0         age          0.026846\n",
       "1         job          0.000000\n",
       "2     marital          0.000000\n",
       "3   education          0.002853\n",
       "4     default          0.000000\n",
       "5     balance          0.001040\n",
       "6     housing          0.066337\n",
       "7        loan          0.003762\n",
       "8     contact          0.119728\n",
       "9         day          0.003512\n",
       "10      month          0.052438\n",
       "11   duration          0.576413\n",
       "12   campaign          0.000982\n",
       "13      pdays          0.078652\n",
       "14   previous          0.016312\n",
       "15   poutcome          0.051127"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creat a dictanary   \n",
    "\n",
    "dict1={\"Features\":X.columns,'Information_Gain':dtc1.feature_importances_}\n",
    "\n",
    "\n",
    "df2=pd.DataFrame(dict1)\n",
    "df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d04dd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #create a tree\n",
    "# #create  a tree \n",
    "# from sklearn import tree\n",
    "# features=X.columns\n",
    "# plt.figure(figsize=(20,20))\n",
    "# _=tree.plot_tree(dtc1,feature_names=features,filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c598f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.78      0.83      1760\n",
      "           1       0.78      0.87      0.83      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1379  381]\n",
      " [ 204 1385]]\n"
     ]
    }
   ],
   "source": [
    "#using 2 techniques to remove overfitting \n",
    "dtc2=DecisionTreeClassifier(random_state=43,min_samples_leaf=45)\n",
    "dtc2=create_model(dtc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "686f7308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      1760\n",
      "           1       0.80      0.82      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1438  322]\n",
      " [ 283 1306]]\n"
     ]
    }
   ],
   "source": [
    "#entropy min samples\n",
    "dtc3=DecisionTreeClassifier(random_state=43,min_samples_leaf=45,criterion='entropy')\n",
    "dtc3=create_model(dtc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b9df8beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.76      0.78      1760\n",
      "           1       0.75      0.79      0.77      1589\n",
      "\n",
      "    accuracy                           0.78      3349\n",
      "   macro avg       0.78      0.78      0.78      3349\n",
      "weighted avg       0.78      0.78      0.78      3349\n",
      "\n",
      "[[1342  418]\n",
      " [ 327 1262]]\n"
     ]
    }
   ],
   "source": [
    "# entropy max depth\n",
    "dtc4=DecisionTreeClassifier(random_state=43,max_depth=5,criterion='entropy')\n",
    "dtc4=create_model(dtc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6ee8bcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensemble techinque\n",
    "#ensemble technique:- train the dataset with mutliple algorithms and taking the combined score of all algorithms\n",
    "#bagging:- no of possibilities it will work on every possibility ,once the data is used it will use it again\n",
    "##pasting it does not work on every possibililties ,once the data is used it is not used again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "24194c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "55521fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensemble  means to train the given dataset on multiple alogrithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0890d125",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an object\n",
    "rfc=RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e8f36cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #bagging feature 1 to 16\n",
    "# for i in range(1,17):\n",
    "#     rfc=RandomForestClassifier(max_features=i,random_state=1)\n",
    "#     print('Max features',i)\n",
    "#     #call function\n",
    "#     rfc=create_model(rfc)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f13405e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.85      1760\n",
      "           1       0.81      0.88      0.84      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1434  326]\n",
      " [ 193 1396]]\n"
     ]
    }
   ],
   "source": [
    "rfc=RandomForestClassifier(max_features=4,random_state=1)\n",
    "rfc=create_model(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "745e2903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Information_Gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>duration</td>\n",
       "      <td>0.362295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>balance</td>\n",
       "      <td>0.089021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>0.088193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>month</td>\n",
       "      <td>0.083337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>day</td>\n",
       "      <td>0.071265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pdays</td>\n",
       "      <td>0.049338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>job</td>\n",
       "      <td>0.039578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>contact</td>\n",
       "      <td>0.038811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>poutcome</td>\n",
       "      <td>0.035680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>campaign</td>\n",
       "      <td>0.033898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>housing</td>\n",
       "      <td>0.033574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>education</td>\n",
       "      <td>0.022345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>previous</td>\n",
       "      <td>0.021356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>marital</td>\n",
       "      <td>0.019575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>loan</td>\n",
       "      <td>0.010357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>default</td>\n",
       "      <td>0.001376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Features  Information_Gain\n",
       "11   duration          0.362295\n",
       "5     balance          0.089021\n",
       "0         age          0.088193\n",
       "10      month          0.083337\n",
       "9         day          0.071265\n",
       "13      pdays          0.049338\n",
       "1         job          0.039578\n",
       "8     contact          0.038811\n",
       "15   poutcome          0.035680\n",
       "12   campaign          0.033898\n",
       "6     housing          0.033574\n",
       "3   education          0.022345\n",
       "14   previous          0.021356\n",
       "2     marital          0.019575\n",
       "7        loan          0.010357\n",
       "4     default          0.001376"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict5={'Features':X.columns,\"Information_Gain\":rfc.feature_importances_}\n",
    "df4=pd.DataFrame(dict5)\n",
    "df4\n",
    "#sorting values\n",
    "df4=df4.sort_values(by='Information_Gain',ascending=False)\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b86ce2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble  import AdaBoostClassifier\n",
    "#create an object for AdaBoostClassifier\n",
    "# ada=AdaBoostClassifier(random_state=1,n_estimators=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4903d245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ada=AdaBoostClassifier(random_state=1,n_estimators=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "44ef92b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #hit and try method  for adaboost classifier\n",
    "# for i in range(1,17):\n",
    "#     ada=AdaBoostClassifier(random_state=1,n_estimators=i)\n",
    "#     print(\"No of estimators:\",i)\n",
    "#     #call function\n",
    "#     ada=create_model(ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "212da09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.76      1760\n",
      "           1       0.72      0.80      0.76      1589\n",
      "\n",
      "    accuracy                           0.76      3349\n",
      "   macro avg       0.76      0.76      0.76      3349\n",
      "weighted avg       0.76      0.76      0.76      3349\n",
      "\n",
      "[[1262  498]\n",
      " [ 310 1279]]\n"
     ]
    }
   ],
   "source": [
    "ada=AdaBoostClassifier(random_state=1,n_estimators=3)\n",
    "ada=create_model(ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d7953761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble  import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9df2dd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1,17):\n",
    "#     gbc=GradientBoostingClassifier(random_state=1,n_estimators=i)\n",
    "#     print(\"No of estimators:\",i)\n",
    "#     gbc=create_model(gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3e83f86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.76      0.80      1760\n",
      "           1       0.76      0.83      0.79      1589\n",
      "\n",
      "    accuracy                           0.80      3349\n",
      "   macro avg       0.80      0.80      0.80      3349\n",
      "weighted avg       0.80      0.80      0.80      3349\n",
      "\n",
      "[[1343  417]\n",
      " [ 266 1323]]\n"
     ]
    }
   ],
   "source": [
    "gbc=GradientBoostingClassifier(random_state=1,n_estimators=14)\n",
    "gbc=create_model(gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "815235fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\programdata\\anaconda3\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.20.3)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.7.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ce894aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a91d4fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function numpy.arange>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c539255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb=XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "58ad0119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.78      0.81      1760\n",
      "           1       0.77      0.83      0.80      1589\n",
      "\n",
      "    accuracy                           0.80      3349\n",
      "   macro avg       0.80      0.80      0.80      3349\n",
      "weighted avg       0.81      0.80      0.80      3349\n",
      "\n",
      "[[1368  392]\n",
      " [ 266 1323]]\n",
      "number 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.79      0.82      1760\n",
      "           1       0.79      0.85      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1395  365]\n",
      " [ 241 1348]]\n",
      "number 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.82      1760\n",
      "           1       0.79      0.84      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1401  359]\n",
      " [ 249 1340]]\n",
      "number 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83      1760\n",
      "           1       0.80      0.84      0.82      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1424  336]\n",
      " [ 247 1342]]\n",
      "number 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.82      0.83      1760\n",
      "           1       0.81      0.84      0.82      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1441  319]\n",
      " [ 256 1333]]\n",
      "number 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.81      0.83      1760\n",
      "           1       0.80      0.85      0.83      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1427  333]\n",
      " [ 235 1354]]\n",
      "number 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.83      1760\n",
      "           1       0.80      0.86      0.83      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1417  343]\n",
      " [ 220 1369]]\n",
      "number 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.81      0.84      1760\n",
      "           1       0.80      0.86      0.83      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1423  337]\n",
      " [ 224 1365]]\n",
      "number 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84      1760\n",
      "           1       0.81      0.86      0.83      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1430  330]\n",
      " [ 221 1368]]\n",
      "number 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84      1760\n",
      "           1       0.80      0.86      0.83      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1423  337]\n",
      " [ 215 1374]]\n",
      "number 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84      1760\n",
      "           1       0.81      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1432  328]\n",
      " [ 211 1378]]\n",
      "number 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84      1760\n",
      "           1       0.81      0.86      0.83      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1432  328]\n",
      " [ 219 1370]]\n",
      "number 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.84      1760\n",
      "           1       0.81      0.86      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1442  318]\n",
      " [ 216 1373]]\n",
      "number 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.85      1760\n",
      "           1       0.81      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.85      0.84      0.84      3349\n",
      "\n",
      "[[1446  314]\n",
      " [ 211 1378]]\n",
      "number 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1760\n",
      "           1       0.82      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1451  309]\n",
      " [ 207 1382]]\n",
      "number 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1760\n",
      "           1       0.82      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1450  310]\n",
      " [ 206 1383]]\n",
      "number 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1760\n",
      "           1       0.82      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1449  311]\n",
      " [ 201 1388]]\n",
      "number 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1760\n",
      "           1       0.82      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1447  313]\n",
      " [ 203 1386]]\n",
      "number 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1760\n",
      "           1       0.82      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1450  310]\n",
      " [ 197 1392]]\n",
      "number 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85      1760\n",
      "           1       0.82      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1453  307]\n",
      " [ 202 1387]]\n",
      "number 21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85      1760\n",
      "           1       0.82      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1457  303]\n",
      " [ 205 1384]]\n",
      "number 22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85      1760\n",
      "           1       0.82      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1457  303]\n",
      " [ 204 1385]]\n",
      "number 23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85      1760\n",
      "           1       0.82      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1461  299]\n",
      " [ 203 1386]]\n",
      "number 24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85      1760\n",
      "           1       0.82      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1458  302]\n",
      " [ 205 1384]]\n",
      "number 25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85      1760\n",
      "           1       0.82      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1457  303]\n",
      " [ 201 1388]]\n",
      "number 26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85      1760\n",
      "           1       0.82      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1457  303]\n",
      " [ 200 1389]]\n",
      "number 27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85      1760\n",
      "           1       0.82      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1461  299]\n",
      " [ 202 1387]]\n",
      "number 28\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85      1760\n",
      "           1       0.82      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1461  299]\n",
      " [ 203 1386]]\n",
      "number 29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85      1760\n",
      "           1       0.82      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1462  298]\n",
      " [ 200 1389]]\n",
      "number 30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86      1760\n",
      "           1       0.83      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1466  294]\n",
      " [ 200 1389]]\n",
      "number 31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86      1760\n",
      "           1       0.82      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1464  296]\n",
      " [ 198 1391]]\n",
      "number 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86      1760\n",
      "           1       0.82      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1464  296]\n",
      " [ 198 1391]]\n",
      "number 33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86      1760\n",
      "           1       0.83      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1465  295]\n",
      " [ 198 1391]]\n",
      "number 34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86      1760\n",
      "           1       0.83      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.86      0.85      0.85      3349\n",
      "\n",
      "[[1466  294]\n",
      " [ 197 1392]]\n",
      "number 35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86      1760\n",
      "           1       0.83      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.86      0.85      0.85      3349\n",
      "\n",
      "[[1468  292]\n",
      " [ 198 1391]]\n",
      "number 36\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86      1760\n",
      "           1       0.83      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.86      0.85      0.85      3349\n",
      "\n",
      "[[1470  290]\n",
      " [ 199 1390]]\n",
      "number 37\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86      1760\n",
      "           1       0.83      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1466  294]\n",
      " [ 199 1390]]\n",
      "number 38\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85      1760\n",
      "           1       0.82      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1461  299]\n",
      " [ 199 1390]]\n",
      "number 39\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85      1760\n",
      "           1       0.82      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1461  299]\n",
      " [ 200 1389]]\n",
      "number 40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86      1760\n",
      "           1       0.83      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.86      0.85      0.85      3349\n",
      "\n",
      "[[1465  295]\n",
      " [ 196 1393]]\n",
      "number 41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86      1760\n",
      "           1       0.82      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.86      0.85      0.85      3349\n",
      "\n",
      "[[1464  296]\n",
      " [ 195 1394]]\n",
      "number 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86      1760\n",
      "           1       0.83      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.86      0.85      3349\n",
      "weighted avg       0.86      0.85      0.85      3349\n",
      "\n",
      "[[1465  295]\n",
      " [ 194 1395]]\n",
      "number 43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86      1760\n",
      "           1       0.83      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.86      0.86      0.85      3349\n",
      "weighted avg       0.86      0.85      0.85      3349\n",
      "\n",
      "[[1464  296]\n",
      " [ 190 1399]]\n",
      "number 44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86      1760\n",
      "           1       0.82      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.86      0.85      0.85      3349\n",
      "\n",
      "[[1464  296]\n",
      " [ 194 1395]]\n",
      "number 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86      1760\n",
      "           1       0.82      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1463  297]\n",
      " [ 197 1392]]\n",
      "number 46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86      1760\n",
      "           1       0.82      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1463  297]\n",
      " [ 198 1391]]\n",
      "number 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86      1760\n",
      "           1       0.83      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1465  295]\n",
      " [ 197 1392]]\n",
      "number 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86      1760\n",
      "           1       0.82      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.86      0.85      0.85      3349\n",
      "\n",
      "[[1464  296]\n",
      " [ 195 1394]]\n",
      "number 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86      1760\n",
      "           1       0.82      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.86      0.86      0.85      3349\n",
      "weighted avg       0.86      0.85      0.85      3349\n",
      "\n",
      "[[1462  298]\n",
      " [ 189 1400]]\n",
      "number 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86      1760\n",
      "           1       0.82      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.86      0.85      3349\n",
      "weighted avg       0.86      0.85      0.85      3349\n",
      "\n",
      "[[1459  301]\n",
      " [ 189 1400]]\n",
      "number 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86      1760\n",
      "           1       0.82      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.86      0.85      3349\n",
      "weighted avg       0.86      0.85      0.85      3349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[1461  299]\n",
      " [ 189 1400]]\n",
      "number 52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86      1760\n",
      "           1       0.82      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.86      0.85      0.85      3349\n",
      "\n",
      "[[1461  299]\n",
      " [ 192 1397]]\n",
      "number 53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86      1760\n",
      "           1       0.82      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.86      0.85      3349\n",
      "weighted avg       0.86      0.85      0.85      3349\n",
      "\n",
      "[[1463  297]\n",
      " [ 192 1397]]\n",
      "number 54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86      1760\n",
      "           1       0.83      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.86      3349\n",
      "   macro avg       0.86      0.86      0.86      3349\n",
      "weighted avg       0.86      0.86      0.86      3349\n",
      "\n",
      "[[1463  297]\n",
      " [ 188 1401]]\n",
      "number 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86      1760\n",
      "           1       0.83      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.86      0.86      0.85      3349\n",
      "weighted avg       0.86      0.85      0.85      3349\n",
      "\n",
      "[[1464  296]\n",
      " [ 190 1399]]\n",
      "number 56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86      1760\n",
      "           1       0.82      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.86      0.85      3349\n",
      "weighted avg       0.86      0.85      0.85      3349\n",
      "\n",
      "[[1463  297]\n",
      " [ 192 1397]]\n",
      "number 57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86      1760\n",
      "           1       0.82      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1462  298]\n",
      " [ 196 1393]]\n",
      "number 58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86      1760\n",
      "           1       0.82      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.86      0.85      0.85      3349\n",
      "\n",
      "[[1464  296]\n",
      " [ 195 1394]]\n",
      "number 59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86      1760\n",
      "           1       0.82      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1463  297]\n",
      " [ 198 1391]]\n",
      "number 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86      1760\n",
      "           1       0.82      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1463  297]\n",
      " [ 197 1392]]\n",
      "number 61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86      1760\n",
      "           1       0.83      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1465  295]\n",
      " [ 197 1392]]\n",
      "number 62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86      1760\n",
      "           1       0.83      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1465  295]\n",
      " [ 198 1391]]\n",
      "number 63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86      1760\n",
      "           1       0.83      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1465  295]\n",
      " [ 198 1391]]\n",
      "number 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86      1760\n",
      "           1       0.82      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1464  296]\n",
      " [ 198 1391]]\n",
      "number 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86      1760\n",
      "           1       0.83      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1466  294]\n",
      " [ 201 1388]]\n",
      "number 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86      1760\n",
      "           1       0.83      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.86      0.85      3349\n",
      "weighted avg       0.86      0.85      0.85      3349\n",
      "\n",
      "[[1469  291]\n",
      " [ 198 1391]]\n",
      "number 67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85      1760\n",
      "           1       0.82      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1460  300]\n",
      " [ 203 1386]]\n",
      "number 68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85      1760\n",
      "           1       0.82      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1461  299]\n",
      " [ 204 1385]]\n",
      "number 69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85      1760\n",
      "           1       0.82      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1463  297]\n",
      " [ 205 1384]]\n",
      "number 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85      1760\n",
      "           1       0.82      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1461  299]\n",
      " [ 207 1382]]\n",
      "number 71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85      1760\n",
      "           1       0.82      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1460  300]\n",
      " [ 207 1382]]\n",
      "number 72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85      1760\n",
      "           1       0.82      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1462  298]\n",
      " [ 202 1387]]\n",
      "number 73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85      1760\n",
      "           1       0.82      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1463  297]\n",
      " [ 202 1387]]\n",
      "number 74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85      1760\n",
      "           1       0.82      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1463  297]\n",
      " [ 202 1387]]\n",
      "number 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86      1760\n",
      "           1       0.82      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1466  294]\n",
      " [ 203 1386]]\n",
      "number 76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85      1760\n",
      "           1       0.83      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1468  292]\n",
      " [ 206 1383]]\n",
      "number 77\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85      1760\n",
      "           1       0.83      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1467  293]\n",
      " [ 207 1382]]\n",
      "number 78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86      1760\n",
      "           1       0.83      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1469  291]\n",
      " [ 205 1384]]\n",
      "number 79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86      1760\n",
      "           1       0.83      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1468  292]\n",
      " [ 204 1385]]\n",
      "number 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86      1760\n",
      "           1       0.83      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1470  290]\n",
      " [ 203 1386]]\n",
      "number 81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86      1760\n",
      "           1       0.83      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1471  289]\n",
      " [ 204 1385]]\n",
      "number 82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86      1760\n",
      "           1       0.83      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1471  289]\n",
      " [ 206 1383]]\n",
      "number 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86      1760\n",
      "           1       0.83      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1473  287]\n",
      " [ 207 1382]]\n",
      "number 84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86      1760\n",
      "           1       0.83      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1472  288]\n",
      " [ 206 1383]]\n",
      "number 85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86      1760\n",
      "           1       0.83      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1472  288]\n",
      " [ 208 1381]]\n",
      "number 86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86      1760\n",
      "           1       0.83      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1473  287]\n",
      " [ 207 1382]]\n",
      "number 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86      1760\n",
      "           1       0.83      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1471  289]\n",
      " [ 204 1385]]\n",
      "number 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86      1760\n",
      "           1       0.83      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1469  291]\n",
      " [ 203 1386]]\n",
      "number 89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85      1760\n",
      "           1       0.82      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1467  293]\n",
      " [ 211 1378]]\n",
      "number 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85      1760\n",
      "           1       0.82      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1467  293]\n",
      " [ 209 1380]]\n",
      "number 91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85      1760\n",
      "           1       0.83      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1468  292]\n",
      " [ 211 1378]]\n",
      "number 92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.85      1760\n",
      "           1       0.83      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1471  289]\n",
      " [ 212 1377]]\n",
      "number 93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86      1760\n",
      "           1       0.83      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1473  287]\n",
      " [ 209 1380]]\n",
      "number 94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86      1760\n",
      "           1       0.83      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1473  287]\n",
      " [ 210 1379]]\n",
      "number 95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86      1760\n",
      "           1       0.83      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1472  288]\n",
      " [ 210 1379]]\n",
      "number 96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86      1760\n",
      "           1       0.83      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1470  290]\n",
      " [ 204 1385]]\n",
      "number 97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86      1760\n",
      "           1       0.83      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.86      0.85      3349\n",
      "weighted avg       0.86      0.85      0.85      3349\n",
      "\n",
      "[[1471  289]\n",
      " [ 199 1390]]\n",
      "number 98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86      1760\n",
      "           1       0.83      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1473  287]\n",
      " [ 206 1383]]\n",
      "number 99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86      1760\n",
      "           1       0.83      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1473  287]\n",
      " [ 206 1383]]\n",
      "number 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86      1760\n",
      "           1       0.83      0.87      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1473  287]\n",
      " [ 203 1386]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,101):\n",
    "    xgb=XGBClassifier(random_state=1,n_estimators=i)\n",
    "    print(\"number\",i)\n",
    "    xgb=create_model(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f14738a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86      1760\n",
      "           1       0.82      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.86      0.86      0.85      3349\n",
      "weighted avg       0.86      0.85      0.85      3349\n",
      "\n",
      "[[1462  298]\n",
      " [ 189 1400]]\n"
     ]
    }
   ],
   "source": [
    "xgb=XGBClassifier(random_state=1,n_estimators=49)\n",
    "xgb=create_model(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4de4286d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.77      0.81      1760\n",
      "           1       0.77      0.84      0.80      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n",
      "[[1356  404]\n",
      " [ 248 1341]]\n",
      "number 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1416  344]\n",
      " [ 269 1320]]\n",
      "number 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.78      0.82      1760\n",
      "           1       0.78      0.86      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1381  379]\n",
      " [ 228 1361]]\n",
      "number 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.81      0.83      1760\n",
      "           1       0.80      0.85      0.82      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1421  339]\n",
      " [ 239 1350]]\n",
      "number 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.83      1760\n",
      "           1       0.79      0.86      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.83      0.83      0.82      3349\n",
      "weighted avg       0.83      0.82      0.82      3349\n",
      "\n",
      "[[1392  368]\n",
      " [ 221 1368]]\n",
      "number 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.81      0.83      1760\n",
      "           1       0.80      0.85      0.83      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1429  331]\n",
      " [ 235 1354]]\n",
      "number 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.79      0.83      1760\n",
      "           1       0.79      0.87      0.83      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.84      0.83      0.83      3349\n",
      "\n",
      "[[1397  363]\n",
      " [ 202 1387]]\n",
      "number 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.80      0.84      1760\n",
      "           1       0.80      0.88      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1409  351]\n",
      " [ 198 1391]]\n",
      "number 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.80      0.84      1760\n",
      "           1       0.80      0.88      0.83      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.84      0.84      0.83      3349\n",
      "weighted avg       0.84      0.83      0.83      3349\n",
      "\n",
      "[[1405  355]\n",
      " [ 198 1391]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    xgb1=XGBClassifier(random_state=1,n_estimators=i,gamma=15)\n",
    "    print(\"number\",i)\n",
    "    xgb1=create_model(xgb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5fe81b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.91      0.80      1760\n",
      "           1       0.86      0.61      0.71      1589\n",
      "\n",
      "    accuracy                           0.77      3349\n",
      "   macro avg       0.79      0.76      0.76      3349\n",
      "weighted avg       0.79      0.77      0.76      3349\n",
      "\n",
      "[[1601  159]\n",
      " [ 618  971]]\n",
      "number 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.86      0.82      1760\n",
      "           1       0.83      0.74      0.78      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.80      0.80      3349\n",
      "weighted avg       0.81      0.81      0.80      3349\n",
      "\n",
      "[[1518  242]\n",
      " [ 408 1181]]\n",
      "number 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1760\n",
      "           1       0.80      0.80      0.80      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n",
      "[[1438  322]\n",
      " [ 325 1264]]\n",
      "number 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1760\n",
      "           1       0.80      0.80      0.80      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n",
      "[[1447  313]\n",
      " [ 311 1278]]\n",
      "number 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1760\n",
      "           1       0.80      0.81      0.81      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n",
      "[[1438  322]\n",
      " [ 299 1290]]\n",
      "number 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      1760\n",
      "           1       0.81      0.83      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1445  315]\n",
      " [ 273 1316]]\n",
      "number 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.83      1760\n",
      "           1       0.80      0.83      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1434  326]\n",
      " [ 264 1325]]\n",
      "number 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      1760\n",
      "           1       0.80      0.83      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.83      0.82      0.82      3349\n",
      "\n",
      "[[1439  321]\n",
      " [ 267 1322]]\n",
      "number 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.82      0.83      1760\n",
      "           1       0.81      0.84      0.82      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1439  321]\n",
      " [ 256 1333]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    xgb2=XGBClassifier(random_state=1,n_estimators=i,eta=0.09)\n",
    "    print(\"number\",i)\n",
    "    xgb2=create_model(xgb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d5433122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.88      0.81      1760\n",
      "           1       0.83      0.70      0.76      1589\n",
      "\n",
      "    accuracy                           0.79      3349\n",
      "   macro avg       0.80      0.79      0.79      3349\n",
      "weighted avg       0.80      0.79      0.79      3349\n",
      "\n",
      "[[1541  219]\n",
      " [ 481 1108]]\n",
      "number 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1760\n",
      "           1       0.81      0.80      0.80      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n",
      "[[1454  306]\n",
      " [ 323 1266]]\n",
      "number 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.83      1760\n",
      "           1       0.80      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1434  326]\n",
      " [ 275 1314]]\n",
      "number 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83      1760\n",
      "           1       0.80      0.84      0.82      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.82      0.83      0.82      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1428  332]\n",
      " [ 254 1335]]\n",
      "number 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83      1760\n",
      "           1       0.80      0.84      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.83      0.82      0.82      3349\n",
      "\n",
      "[[1418  342]\n",
      " [ 248 1341]]\n",
      "number 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83      1760\n",
      "           1       0.80      0.84      0.82      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1429  331]\n",
      " [ 253 1336]]\n",
      "number 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83      1760\n",
      "           1       0.80      0.84      0.82      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1430  330]\n",
      " [ 251 1338]]\n",
      "number 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.82      1760\n",
      "           1       0.79      0.85      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1397  363]\n",
      " [ 233 1356]]\n",
      "number 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.83      1760\n",
      "           1       0.80      0.85      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.83      0.83      0.82      3349\n",
      "weighted avg       0.83      0.82      0.82      3349\n",
      "\n",
      "[[1413  347]\n",
      " [ 240 1349]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    xgb3=XGBClassifier(random_state=1,n_estimators=i,eta=0.10,gamma=10)  #eta learning rate\n",
    "    print(\"number\",i)\n",
    "    xgb3=create_model(xgb3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5d74dda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.90      0.81      1760\n",
      "           1       0.86      0.63      0.73      1589\n",
      "\n",
      "    accuracy                           0.77      3349\n",
      "   macro avg       0.79      0.77      0.77      3349\n",
      "weighted avg       0.79      0.77      0.77      3349\n",
      "\n",
      "[[1590  170]\n",
      " [ 584 1005]]\n",
      "number 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1760\n",
      "           1       0.81      0.78      0.79      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n",
      "[[1469  291]\n",
      " [ 352 1237]]\n",
      "number 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1760\n",
      "           1       0.80      0.81      0.80      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n",
      "[[1432  328]\n",
      " [ 302 1287]]\n",
      "number 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1760\n",
      "           1       0.80      0.82      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1445  315]\n",
      " [ 291 1298]]\n",
      "number 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      1760\n",
      "           1       0.80      0.83      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1437  323]\n",
      " [ 267 1322]]\n",
      "number 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.83      1760\n",
      "           1       0.80      0.83      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1429  331]\n",
      " [ 267 1322]]\n",
      "number 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.83      1760\n",
      "           1       0.79      0.85      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1413  347]\n",
      " [ 245 1344]]\n",
      "number 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83      1760\n",
      "           1       0.80      0.85      0.82      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1419  341]\n",
      " [ 243 1346]]\n",
      "number 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83      1760\n",
      "           1       0.80      0.84      0.82      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1428  332]\n",
      " [ 247 1342]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    xgb4=XGBClassifier(random_state=1,n_estimators=i,eta=0.10,gamma=i)  #eta learning rate\n",
    "    print(\"number\",i)\n",
    "    xgb4=create_model(xgb4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0047a4",
   "metadata": {},
   "source": [
    "#what is hyperplane \n",
    "# it is decision boundary that seperates both classes\n",
    "# if graph is a 2D, then hyperplane will be 1D\n",
    "# if graph is a 3D them hyperplane will be 2D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc1dac8",
   "metadata": {},
   "source": [
    "# support vector are those datapoint that are closes to hyperplane  distance formula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7375d8",
   "metadata": {},
   "source": [
    "# more distance hyperplane best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade4e4b3",
   "metadata": {},
   "source": [
    "# margins\n",
    "# In support vector machine the goal is to find the best hyperplane that seperates the classes given in the dataset\n",
    "\n",
    "# The hyperplane is the decision boundary that maximize the margin\n",
    "#There are 2type of Margins in SVM:\n",
    "#hard margin\n",
    "#soft margin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7432379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The hyperplane is the decision boundary that maximize the margin\n",
    "# #There are 2type of Margins in SVM:\n",
    "# # Hard Margin : in hard margin svm we assume that linearly seperable. The objective is find best hyperplane that maximize the margin correctly\n",
    "# .This approach is called had margin because it enforces a strict seperation between clsases and doest not allow mis calculation (overfitting)\n",
    "\n",
    "# #soft margin : Int soft margin the svm allows some mis calculation to occur.The objective is to find the hyperplane\n",
    "# that maxmizes the margin while also allowing some misclassification to happen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df210b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPER PL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
